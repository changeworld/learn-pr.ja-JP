ネットワーク パフォーマンスはユーザー エクスペリエンスに大きな影響を及ぼす可能性があります。 多数の異なるサービスを使用した複雑なアーキテクチャにおいては、各ホップでの待ち時間を最小限に抑えることが、全体のパフォーマンスを大きく左右します。 このユニットでは、ネットワーク待ち時間の重要性と、使用するアーキテクチャでのネットワーク待ち時間を削減する方法について説明します。 また、Azure ユーザーと Azure との間の待ち時間だけでなく、Azure リソース間のネットワーク待ち時間を最小限に抑えるために、Lamna Healthcare がどのように戦略を採用したかについても説明します。

## <a name="the-importance-of-network-latency"></a>ネットワーク待ち時間の重要性

待ち時間は、遅延の測定基準です。 ネットワーク待ち時間は、なんらかのネットワーク インフラストラクチャを介してソースから宛先に到達するために必要な時間です。 この所要時間は一般的にラウンドトリップ遅延として知られています。ラウンドトリップ遅延とは、ソースから宛先に到達し、再び戻ってくるのにかかる時間です。

従来のデータ センター環境では、多くの場合にリソースは同じ場所と共通のインフラストラクチャ群を共有しているため、待ち時間が最小限に抑えられる可能性があります。 リソースが物理的に近い場所にあれば、ソースから宛先に到達するためにかかる時間は短くなります。

それに比べて、クラウド環境はスケールに対応できるように構築されています。 クラウドでホストされたリソースは、同じラックやデータ センター、同じリージョン内に存在するとは限りません。 この分散型アプローチが、ネットワーク通信のラウンドトリップ時間に影響を与える可能性があります。 すべての Azure リージョンは高速なファイバー バックボーンで相互接続されていますが、それでも光の速度が物理的な限界です。 異なる物理的な場所にあるサービス間の呼び出しでは、やはり、それらの場所間の距離に直接関係したネットワーク待ち時間が発生します。

さらに、アプリケーションの通信量が多いほど、必要なラウンドトリップの回数も増えます。 1 回のラウンドトリップに伴う待ち時間がラウンドトリップごとに付加されて、全体的な待ち時間が増加します。

![NetworkLatency](../media/networkLatency.png)

では、Azure リソース間のパフォーマンスと、エンド ユーザーから Azure リソースまでのパフォーマンスを改善する方法を見てみましょう。

## <a name="latency-amongst-multiple-azure-resources"></a>複数の Azure リソース間の待ち時間

Lamna Healthcare では、Azure の西ヨーロッパ リージョンにある 1 台の Web サーバーと 1 つのデータベースを使用して、新しい患者予約システムのパイロット運用を実施しようとしています。 同じリージョンにある Azure Blob Storage から Web サイトに静的なメディア資産 (イメージ、JavaScript、スタイルシート) を取得します。 このアーキテクチャでは、リソースが Azure リージョンの内部に併置されているため、データが通信回線上にある時間が最小限に抑えられます。

システムのパイロット運用は順調に進み、オーストラリアのユーザーにまで拡大されました。 それらのユーザーが Web サイトを閲覧すると、アイルランドからオーストラリアまでのラウンドトリップ時間が発生し、ネットワーク待ち時間によってエンド ユーザー エクスペリエンスが低下します。

ユーザーの待ち時間を削減するため、Lamna Healthcare チームは、オーストラリア東部リージョンにおいて、追加のフロントエンド インスタンスとストレージ アカウントをホストすることにしました。 この設計では、Web サーバーからエンド ユーザーにコンテンツを返すのにかかる時間の削減が期待できる一方、オーストラリア東部のフロントエンド Web サーバーと西ヨーロッパのデータベースとの間の通信に長い待ち時間が存在するため、エクスペリエンスの低下はまだ改善されません。

残された待ち時間を削減できる方法がいくつかあります。

* オーストラリア東部にデータベースの読み取りレプリカを作成します。 これにより、読み取りのパフォーマンスは向上しますが、書き込みにはまだ待ち時間が伴います。 Azure SQL Database の geo レプリケーションにより、読み取りレプリカが実現します。
* Azure SQL データ同期機能を使用してリージョン間でデータを同期します。
* Azure Cosmos DB などのグローバル分散データベースを使用します。 これにより、場所に関係なく読み取りと書き込みの両方を実行できるようになります。

ここでの目標は、アプリケーションの各レイヤー間のネットワーク待ち時間を最小限に抑えることです。 これをどのように解決するかは実際のアプリケーションとデータのアーキテクチャによって異なりますが、Azure には、これを解決するメカニズムが複数のサービス上に用意されています。

## <a name="latency-in-the-context-of-users-to-azure"></a>Azure に接続するユーザーの待ち時間

Azure リソース間の待ち時間を見てきましたが、ユーザーとクラウド アプリケーションとの間の待ち時間も考慮する必要があります。 ユーザーへのフロントエンド ユーザー インターフェイスのデリバリーを最適化する必要があります。 エンド ユーザーとアプリケーションとの間のネットワーク パフォーマンスを改善する方法を見てみましょう。

### <a name="use-a-dns-load-balancer-for-endpoint-path-optimization"></a>エンドポイント パスの最適化に DNS ロード バランサーを使用する

Lamna Healthcare の例では、既に説明したように、チームはオーストラリア東部に追加の Web フロントエンド ノードを作成しました。 ただし、エンド ユーザーは、どのフロントエンド エンドポイントを使用するかを明示的に指定する必要があります。 ソリューションの設計者として、Lamna Healthcare はユーザーにとってのエクスペリエンスをできる限りスムーズにしたいと考えています。

Azure Traffic Manager が役に立つ可能性があります。 Azure Traffic Manager は DNS ベースのロード バランサーです。これを使用すると、Azure リージョン内および Azure リージョン間でのトラフィックの分散が可能になります。 ユーザーに Web フロントエンドの特定のインスタンスを選択してもらわなくても、Azure Traffic Manager を使用すれば、次のようないくつかの特性に基づいてユーザーをルーティングすることができます。

* **優先度** - フロントエンド インスタンスの番号付きリストを指定します。 最も優先度が高いインスタンスが利用不可の場合には、Traffic Manager によって、利用可能な次のインスタンスにユーザーがルーティングされます。
* **重み付け** - 各フロントエンド インスタンスに重みを設定します。 それらの定義済み比率に従い、Traffic Manager によってトラフィックが分散されます。
* **パフォーマンス** - Azure Traffic Manager により、ユーザーはネットワーク待ち時間に基づいて最も近いフロントエンド インスタンスにルーティングされます。
* **地理** - フロントエンド デプロイの地理的リージョンを設定し、データ主権規制やコンテンツのローカライズに基づいてユーザーをルーティングすることができます。

Traffic Manager プロファイルをネストすることもできます。 最初は、地理的ルーティングを使用して異なる複数の地理的な場所 (たとえば、ヨーロッパとオーストラリア) の間でユーザーをルーティングし、次にパフォーマンス ルーティングという方法を使用して、ローカル フロントエンド デプロイにルーティングすることができます。

Lamna Healthcare が西ヨーロッパとオーストラリアに Web フロントエンドをデプロイしたとします。 西ヨーロッパにプライマリ デプロイと共に Azure SQL Database をデプロイし、オーストラリア東部に読み取りレプリカをデプロイしたと仮定します。 また、アプリケーションからローカルの SQL インスタンスに接続して読み取りクエリを実行できると仮定しましょう。

チームは Azure Traffic Manager をパフォーマンス モードでデプロイし、Traffic Manager プロファイルとしてフロントエンド インスタンスを 2 つ追加します。 エンド ユーザーがカスタム ドメイン名 (たとえば lamnahealthcare.com) にナビゲートすると、Azure Traffic Manager にルーティングされます。 次に、Azure Traffic Manager から、ネットワーク待ち時間のパフォーマンスが最適であるかどうかに基づいて、西ヨーロッパまたはオーストラリア東部のフロントエンドの DNS 名が返されます。

重要なこととして、この負荷分散は DNS を経由してのみ処理されることに注意してください。ここではインライン負荷分散やキャッシングは実行されず、単純にユーザーに最も近いフロントエンドの DNS 名が Traffic Manager から返されます。

### <a name="use-cdn-to-cache-content-close-to-users"></a>CDN を使用してユーザーに近いコンテンツをキャッシュする

Web サイトでは、何らかの形式の静的コンテンツ (ページ全体、またはイメージやビデオなどの資産) が使用されると考えられます。 Azure CDN などのコンテンツ配信ネットワーク (CDN) を使用することで、このコンテンツをより高速にユーザーに配信できます。 

Lamna が Azure CDN にコンテンツをデプロイすると、それらの項目は世界中の複数のサーバーにコピーされます。 それらの項目の 1 つとして、Blob Storage から提供される `HowToCompleteYourBillingForms.MP4` というビデオがあるとします。 そしてチームは、各ユーザーのビデオへのリンクが (Blob Storage を参照するのではなく) 実際にはそのユーザーに最も近い CDN エッジ サーバーを参照するように、Web サイトを構成します。 このアプローチでは、コンテンツと宛先の距離が近くなり、待ち時間が削減されてユーザー エクスペリエンスが向上します。

![CDNExample](../media/cdnSketch.png)

コンテンツ配信ネットワークは、キャッシュされた動的コンテンツをホストするために使用することもできます。__ ただし、キャッシュされたコンテンツはソースと比較して古い可能性があるため、さらに追加の配慮が必要です。 コンテンツの期限切れは、Time to Live (TTL) を設定することによって制御できます。 TTL の値が大きすぎる場合は、古いコンテンツが表示される可能性があり、そのためにキャッシュを消去することが必要になります。

キャッシュされたコンテンツを処理する方法として、**動的サイトの高速化**と呼ばれる機能を使用する方法があります。この機能を使用すると、動的コンテンツを含む Web ページのパフォーマンスを高めることができます。 動的サイトの高速化により、ソリューションに含まれるその他のサービス (たとえば API エンドポイント) への、待ち時間の少ないパスを提供することもできます。

### <a name="use-expressroute-for-connectivity-from-on-premises-to-azure"></a>オンプレミスから Azure への接続に ExpressRoute を使用する

オンプレミス環境から Azure へのネットワーク接続を最適化することも重要です。 アプリケーションに接続するユーザーに対しては、仮想マシン上でホストされているか、Azure App Service のような PaaS オファーによってホストされているかにかかわらず、アプリケーションへの接続を確実に最適化する必要があります。 

ユーザーをサービスに接続する場合、パブリック インターネットを使用することは常に可能ですが、インターネットのパフォーマンスは一定ではなく、外部の問題によって影響されることがあります。 さらに、すべてのサービスをインターネット上に公開することを希望しておらず、Azure リソースへの非公開の接続を使用したい場合があります。

インターネットを使用したサイト間の VPN もオプションの 1 つですが、高スループットのアーキテクチャの場合、VPN のオーバーヘッドとインターネットの可変性によって待ち時間が大幅に増加する可能性があります。

Azure ExpressRoute が役に立ちます。 ExpressRoute はネットワークと Azure との間の、非公開の専用接続です。これを使用すると、パフォーマンスが保証され、エンド ユーザーがすべての Azure リソースへの最適なパスを確実に使用できるようになります。

![ExpressRoute](../media/expressroute-connection-overview.png)

もう一度 Lamna のシナリオを見てみると、Lamna は施設内のエンド ユーザー エクスペリエンスをさらに改善することに決めました。そのために、ExpressRoute の回線をオーストラリア東部と西ヨーロッパの両方にプロビジョニングし、エンド ユーザーが予約システムに直接接続できるようにすると共に、アプリケーションの待ち時間が可能な限り少なくなるようにします。

## <a name="summary"></a>まとめ

可能な最良のパフォーマンスをエンド ユーザーが確実に得られるようにするには、ネットワーク待ち時間がアーキテクチャに与える影響を考慮することが重要です。 エンド ユーザーと Azure との間および Azure リソース間のネットワーク待ち時間を削減するための、いくつかのオプションについて説明しました。 次に、ストレージのパフォーマンスの最適化について説明します。