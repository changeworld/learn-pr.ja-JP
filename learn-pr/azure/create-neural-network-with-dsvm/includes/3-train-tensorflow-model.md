### <a name="train-a-tensorflow-model"></a><span data-ttu-id="3d3a2-101">TensorFlow モデルをトレーニングする</span><span class="sxs-lookup"><span data-stu-id="3d3a2-101">Train a TensorFlow model</span></span>

<span data-ttu-id="3d3a2-102">このユニットでは、[TensorFlow](https://www.tensorflow.org/) を使用してビルドされた画像分類モデルを、ホットドッグが入った画像を認識するようにトレーニングします。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-102">In this unit, you will train an image-classification model built with [TensorFlow](https://www.tensorflow.org/) to recognize images that contain hot dogs.</span></span> <span data-ttu-id="3d3a2-103">モデルをゼロから作成すると、膨大な量のコンピューティング能力と数十万もの画像が必要になるため、[転移学習](https://en.wikipedia.org/wiki/Transfer_learning)として知られている既存のモデルをカスタマイズします。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-103">Rather than create the model from scratch, which would require vast amounts of computing power and tens or hundreds of thousands of images, you will customize a preexisting model, a practice known as [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning).</span></span> <span data-ttu-id="3d3a2-104">転移学習を使用すると、一般的なノート パソコンや PC で数十個のイメージだけを使用して、わずか数分間で高レベルの精度を実現できます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-104">Transfer learning allows you to achieve high levels of accuracy with as little as a few minutes of training time on a typical laptop or PC and as few as several dozen images.</span></span>

<span data-ttu-id="3d3a2-105">ディープ ラーニングとの関係において、転移学習は、イメージの分類と、問題のドメインのネットワークをカスタマイズするレイヤーの追加 (たとえばイメージにホットドッグが含まれているか含まれていないかで 2 つのグループに分類する) を実行するように事前にトレーニングされたディープ ニューラル ネットワークから始まります。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-105">In the context of deep learning, transfer learning involves starting with a deep neural network that is pretrained to perform image classification and adding a layer that customizes the network for your problem domain — for example, to classify images into two groups: those that contain hot dogs, and those that do not.</span></span> <span data-ttu-id="3d3a2-106"><https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models.> では、20 を超える事前トレーニング済みの TensorFlow イメージ分類モデルを入手できます。[Inception](https://arxiv.org/abs/1512.00567) と [ResNet](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035) モデルが高い精度とそれに応じた高いリソース要件によって特徴付けられているのに対し、MobileNet モデルは精度と引き換えにコンパクトさと電源効率が高くなっており、モバイル デバイスでの使用を考慮して開発されました。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-106">More than 20 pretrained TensorFlow image-classification models are available at <https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models.> The [Inception](https://arxiv.org/abs/1512.00567) and [ResNet](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035) models are characterized by higher accuracy and commensurately higher resource requirements, while the MobileNet models trade accuracy for compactness and power efficiency and were developed with mobile devices in mind.</span></span> <span data-ttu-id="3d3a2-107">これらのモデルはいずれもディープ ラーニング コミュニティではよく知られており、多くのコンペティションや実際のアプリケーションで使用されています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-107">All of these models are well known in the deep-learning community and have been used in a number of competitions as well as in real-world applications.</span></span> <span data-ttu-id="3d3a2-108">ここでは、精度とトレーニング時間の妥当なバランスを取るため、MobileNet モデルのうちの 1 つをニューラル ネットワークの基礎として使用します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-108">You will use one of the MobileNet models as the basis for your neural network in order to strike a reasonable balance between accuracy and training time.</span></span>

<span data-ttu-id="3d3a2-109">モデルのトレーニングは、基本モデルをダウンロードして、ドメイン固有のイメージとラベルを使ってトレーニングされたレイヤーを追加する Python スクリプトを実行するだけです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-109">Training the model involves little more than running a Python script that downloads the base model and adds a layer trained with domain-specific images and labels.</span></span> <span data-ttu-id="3d3a2-110">必要なスクリプトは GitHub で入手できます。使用するイメージは、[Kaggle](https://www.kaggle.com) から入手可能なパブリック ドメインの数千の食品イメージから集められました。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-110">The script you need is available on GitHub, and the images you will use were assembled from thousands of public-domain food images available from [Kaggle](https://www.kaggle.com).</span></span>

1. <span data-ttu-id="3d3a2-111">Data Science VM で、画面の下部にあるターミナル アイコンをクリックして、ターミナル ウィンドウを開きます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-111">In the Data Science VM, click the Terminal icon at the bottom of the screen to open a terminal window.</span></span>

    ![ターミナル ウィンドウを起動する](../media-draft/3-launch-terminal.png)

    <span data-ttu-id="3d3a2-113">_"ターミナル ウィンドウを起動する"_</span><span class="sxs-lookup"><span data-stu-id="3d3a2-113">_Launching a terminal window_</span></span>

1. <span data-ttu-id="3d3a2-114">ターミナル ウィンドウで、次のコマンドを実行して、"notebooks" フォルダーに移動します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-114">Execute the following command in the terminal window to navigate to the "notebooks" folder:</span></span>

    ```bash
    cd notebooks
    ```
    <span data-ttu-id="3d3a2-115">このフォルダーには、DSVM 用に収集されたサンプルの Jupyter ノートブックがあらかじめ入っています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-115">This folder is prepopulated with sample Jupyter notebooks curated for the DSVM.</span></span>

1. <span data-ttu-id="3d3a2-116">次のコマンドを使用して GitHub から "TensorFlow for Poets" リポジトリを複製します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-116">Now use the following command to clone the "TensorFlow for Poets" repository from GitHub:</span></span>

    ```bash
    git clone https://github.com/googlecodelabs/tensorflow-for-poets-2
    ```
    > <span data-ttu-id="3d3a2-117">**ヒント**: クリップボードにこの行をコピーして、**Shift + Ins** を使用してターミナル ウィンドウに貼り付けることができます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-117">**Tip**: You can copy this line to the clipboard, and then use **Shift+Ins** to paste it into the terminal window.</span></span>

    <span data-ttu-id="3d3a2-118">このリポジトリには、転移学習モデルを作成するためのスクリプトや、イメージを分類するためにトレーニング済みモデルを呼び出すスクリプトなどが含まれています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-118">This repo contains scripts for creating transfer-learning models, invoking a trained model in order to classify an image, and more.</span></span> <span data-ttu-id="3d3a2-119">これは [Google Codelabs](https://codelabs.developers.google.com/) の一部です。Google Codelabs には、TensorFlow やその他の Google のツールおよび API について関心のあるソフトウェア開発者向けのさまざまなリソースとハンズオン ラボが含まれています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-119">It is part of [Google Codelabs](https://codelabs.developers.google.com/), which contains a variety of resources and hands-on labs for software developers interested in learning about TensorFlow and other Google tools and APIs.</span></span>

1. <span data-ttu-id="3d3a2-120">複製が完了したら、複製したモデルを含むフォルダーに移動します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-120">Once cloning is complete, navigate to the folder containing the cloned model:</span></span>

    ```bash
    cd tensorflow-for-poets-2
    ```

1. <span data-ttu-id="3d3a2-121">次のコマンドを使用して、モデルのトレーニングに使用するイメージをダウンロードします。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-121">Use the following command to download the images that will be used to train the model:</span></span>

    ```bash
    wget https://topcs.blob.core.windows.net/public/tensorflow-resources.zip -O temp.zip; unzip temp.zip -d tf_files; rm temp.zip
    ```

    <span data-ttu-id="3d3a2-122">このコマンドにより、数百の食品イメージ (このうちの半分にはホットドッグが入っており、もう半分には入っていません) を含む zip ファイルがダウンロードされ、それらが "tf_files" という名前のサブディレクトリにコピーされます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-122">This command downloads a zip file containing hundreds of food images — half containing hot dogs, and half that do not — and copies them into the subdirectory named "tf_files."</span></span>

1. <span data-ttu-id="3d3a2-123">画面の下部にある [ファイル マネージャー] アイコンをクリックして、[ファイル マネージャー] ウィンドウを開きます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-123">Click the File Manager icon at the bottom of the screen to open a File Manager window.</span></span>

    ![ファイル マネージャーを起動する](../media-draft/3-launch-file-manager.png)

    <span data-ttu-id="3d3a2-125">_"ファイル マネージャーを起動する"_</span><span class="sxs-lookup"><span data-stu-id="3d3a2-125">_Launching File Manager_</span></span>

1. <span data-ttu-id="3d3a2-126">ファイル マネージャーで、"notebooks/tensorflow-for-poets-2/tf_files" フォルダーに移動します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-126">In File Manager, navigate to the "notebooks/tensorflow-for-poets-2/tf_files" folder.</span></span> <span data-ttu-id="3d3a2-127">フォルダーに "hot_dog" と "not_hot_dog" という名前のサブディレクトリのペアが含まれていることを確認します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-127">Confirm that the folder contains a pair of subdirectories named "hot_dog" and "not_hot_dog."</span></span> <span data-ttu-id="3d3a2-128">前者にはホットドッグが入った数百のイメージが格納されており、後者にはホットドッグが**入っていない**同じ数のイメージが格納されています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-128">The former contains several hundred images containing hot dogs, while the latter contains an equal number of images that do **not** contain hot dogs.</span></span> <span data-ttu-id="3d3a2-129">"hot_dog" フォルダー内のイメージを参照して、その見た目の感触をつかみます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-129">Browse the images in the "hot_dog" folder to get a feel for what they look like.</span></span> <span data-ttu-id="3d3a2-130">"Not_hot_dog" フォルダー内のイメージも確認します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-130">Check out the images in the "not_hot_dog" folder as well.</span></span>

    > <span data-ttu-id="3d3a2-131">イメージにホットドッグが含まれているかどうかをニューラル ネットワークが判断できるように、ホットドッグが含まれているイメージと含まれていないイメージを使ってトレーニングします。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-131">In order to train a neural network to determine whether an image contains a hot dog, you will train it with images that contain hot dogs as well as images that do not contain hot dogs.</span></span>

    !["hot_dog" フォルダー内のイメージ](../media-draft/3-hot-dog-images.png)

    <span data-ttu-id="3d3a2-133">*"hot_dog" フォルダー内の画像*</span><span class="sxs-lookup"><span data-stu-id="3d3a2-133">*Images in the "hot_dog" folder*</span></span>

    <span data-ttu-id="3d3a2-134">また、**retrained_labels_hotdog.txt** という名前のテキスト ファイルがフォルダーに含まれていることを確認します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-134">Also, confirm that the folder contains a text file named **retrained_labels_hotdog.txt**.</span></span> <span data-ttu-id="3d3a2-135">このファイルは、トレーニング画像が含まれているサブディレクトリを識別します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-135">This file identifies the subdirectories containing the training images.</span></span> <span data-ttu-id="3d3a2-136">これはモデルをトレーニングする Python スクリプトによって使用されます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-136">It is used by the Python script that trains the model.</span></span> <span data-ttu-id="3d3a2-137">スクリプトによって、テキスト ファイル (テキスト ファイルの名前はスクリプトに渡されるパラメーターです) で指定される各サブディレクトリ内のファイルが列挙され、これらのファイルがネットワークのトレーニングのために使用されます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-137">The script enumerates the files in each subdirectory identified in the text file (the text file's name is a parameter passed to the script) and uses those files to train the network.</span></span>

1. <span data-ttu-id="3d3a2-138">2 番目のターミナル ウィンドウを開き、"notebooks/tensorflow-for-poets-2" フォルダー (最初のターミナル ウィンドウで開いたのと同じフォルダー) に移動します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-138">Open a second terminal window and navigate to the "notebooks/tensorflow-for-poets-2" folder — the same one that is open in the first terminal window.</span></span> <span data-ttu-id="3d3a2-139">次に、次のコマンドを使用して [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) を起動します。これは、TensorFlow モデルを視覚化し、転移学習プロセスの分析情報を得るためのツール セットです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-139">Then, use the following command to launch [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard), which is a set of tools used to visualize TensorFlow models and gain insight into the transfer-learning process:</span></span>

     ```bash
     tensorboard --logdir tf_files/training_summaries
     ```

     > <span data-ttu-id="3d3a2-140">TensorBoard のインスタンスが既に実行されている場合には、このコマンドは失敗します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-140">This command will fail if there is already an instance of TensorBoard running.</span></span> <span data-ttu-id="3d3a2-141">ポート 6006 が既に使用されていることがわかっている場合には、```pkill -f "tensorboard"``` コマンドを使用して既存のプロセスを強制終了します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-141">If you are notified that port 6006 is already in use, use a ```pkill -f "tensorboard"``` command to kill the existing process.</span></span> <span data-ttu-id="3d3a2-142">次に、```tensorboard``` コマンドをもう一度実行します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-142">Then, execute the ```tensorboard``` command again.</span></span>

1. <span data-ttu-id="3d3a2-143">元のターミナル ウィンドウに戻り、次のコマンドを実行します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-143">Switch back to the original terminal window and execute the following commands:</span></span>

    ```bash
    IMAGE_SIZE=224;
    ARCHITECTURE="mobilenet_0.50_${IMAGE_SIZE}";
    ```

    <span data-ttu-id="3d3a2-144">これらのコマンドにより、トレーニング イメージの解像度と、ニューラル ネットワークの基礎となる基本モデルを指定する環境変数が初期化されます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-144">These commands initialize environment variables specifying the resolution of the training images and the base model that your neural network will build upon.</span></span> <span data-ttu-id="3d3a2-145">IMAGE_SIZE の有効な値は、128、160、192、224 です。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-145">Valid values for IMAGE_SIZE are 128, 160, 192, and 224.</span></span> <span data-ttu-id="3d3a2-146">値が大きいほどトレーニング時間は長くなりますが、分類の精度も高まります。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-146">Higher values increase the training time, but also increase the accuracy of the classifier.</span></span>

1. <span data-ttu-id="3d3a2-147">次に、次のコマンドを実行して、転移学習プロセスを開始します。つまり、ダウンロードしたイメージを使って、モデルをトレーニングします。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-147">Now execute the following command to start the transfer-learning process — that is, to train the model with the images you downloaded:</span></span>

    ```bash
    python scripts/retrain.py \
    --bottleneck_dir=tf_files/bottlenecks \
    --how_many_training_steps=500 \
    --model_dir=tf_files/models/ \
    --summaries_dir=tf_files/training_summaries/"${ARCHITECTURE}" \
    --output_graph=tf_files/retrained_graph_hotdog.pb \
    --output_labels=tf_files/retrained_labels_hotdog.txt \
    --architecture="${ARCHITECTURE}" \
    --image_dir=tf_files \
    --testing_percentage=15 \
    --validation_percentage=15
    ```

    <span data-ttu-id="3d3a2-148">**retrain.py** は、ダウンロードしたリポジトリ内のスクリプトの 1 つです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-148">**retrain.py** is one of the scripts in the repo that you downloaded.</span></span> <span data-ttu-id="3d3a2-149">これは複雑で、1,000 行を超えるコードとコメントで構成されています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-149">It is complex, comprising more than 1,000 lines of code and comments.</span></span> <span data-ttu-id="3d3a2-150">そのジョブは、```--architecture``` スイッチで指定されたモデルをダウンロードして、それを ```--image_dir``` スイッチで指定されたディレクトリのサブディレクトリにあるイメージを使用してトレーニングされた新しい層に追加することです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-150">Its job is to download the model specified with the ```--architecture``` switch and add to it a new layer trained with the images found in subdirectories of the directory specified with the ```--image_dir``` switch.</span></span> <span data-ttu-id="3d3a2-151">各イメージは、それぞれが格納されているサブディレクトリの名前 (この場合は、"hot_dog" または "not_hot_dog" のいずれか) でラベル付けされ、変更されたニューラル ネットワークがイメージ入力をホットドッグのイメージ ("hot_dog") またはホットドッグなしのイメージ ("not_hot_dog") に分類できるようにします。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-151">Each image is labeled with the name of the subdirectory in which it is located — in this case, either "hot_dog" or "not_hot_dog" — enabling the modified neural network to classify images input to it as hot-dog images ("hot_dog") or not-hot-dog images ("not_hot_dog").</span></span> <span data-ttu-id="3d3a2-152">トレーニング セッションからの出力は、**retrained_graph_hotdog.pb** という名前の TensorFlow モデル ファイルです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-152">The output from the training session is a TensorFlow model file named **retrained_graph_hotdog.pb**.</span></span> <span data-ttu-id="3d3a2-153">名前と場所は、```--output_graph``` スイッチで指定されます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-153">The name and location are specified in the ```--output_graph``` switch.</span></span>

1. <span data-ttu-id="3d3a2-154">トレーニングが完了するまで待ちます。通常は 5 分未満で完了します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-154">Wait for training to complete; it should take less than five minutes.</span></span> <span data-ttu-id="3d3a2-155">次に、出力を確認して、モデルの精度を判断します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-155">Then, check the output to determine the accuracy of the model.</span></span> <span data-ttu-id="3d3a2-156">トレーニング プロセスには多少の推定が入っているため、実際の結果は以下と多少異なる場合があります。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-156">Your result may vary slightly from the one below because the training process involves a small amount of random estimation.</span></span>

      ![モデルの精度を計測する](../media-draft/3-running-transfer-learning.png)

1. <span data-ttu-id="3d3a2-158">デスクトップの下部にあるブラウザー アイコンをクリックして、Data Science VM にインストールされているブラウザーを開きます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-158">Click the browser icon at the bottom of the desktop to open the browser installed in the Data Science VM.</span></span> <span data-ttu-id="3d3a2-159">次に、<http://0.0.0.0:6006> に移動して Tensorboard に接続します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-159">Then, navigate to <http://0.0.0.0:6006> to connect to Tensorboard.</span></span>

    ![Firefox を起動する](../media-draft/3-launch-firefox.png)

1. <span data-ttu-id="3d3a2-161">"accuracy_1" というラベルが付いたグラフを調べます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-161">Inspect the graph labeled "accuracy_1."</span></span> <span data-ttu-id="3d3a2-162">青い線は、```how_many_training_steps``` スイッチで指定された 500 のトレーニング ステップを経て達成された精度を示しています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-162">The blue line depicts the accuracy achieved over time as the 500 training steps specified with the ```how_many_training_steps``` switch are executed.</span></span> <span data-ttu-id="3d3a2-163">このメトリックは、トレーニングの進行とともにモデルの精度がどのように進化しているかを示すため、重要です。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-163">This metric is important, because it shows how the accuracy of the model evolves as training progresses.</span></span> <span data-ttu-id="3d3a2-164">同じくらい重要なのは、青の線とオレンジの線の間の距離です。これは、発生したオーバーフィットの量を数値化したもので、常に最小限に抑える必要があります。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-164">Equally important is the distance between the blue and orange lines, which quantifies the amount of overfitting that occurred and should always be minimized.</span></span> <span data-ttu-id="3d3a2-165">[オーバーフィット](https://en.wikipedia.org/wiki/Overfitting)は、モデルが、トレーニングに使用したイメージはうまく分類できるようになったが、示された他のイメージはそれほどうまく分類できないことを意味します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-165">[Overfitting](https://en.wikipedia.org/wiki/Overfitting) means the model is adept at classifying the images it was trained with, but not as adept at classifying other images presented to it.</span></span> <span data-ttu-id="3d3a2-166">ここでの結果は、オレンジの線 (トレーニング イメージを使って達成された "トレーニング" 精度) と青の線 (トレーニング セット以外のイメージを使ってテストした場合に達成された "検証" 精度) との差が 10% 未満なので、許容範囲内です。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-166">The results here are acceptable, because there is a difference of less than 10% between the orange line (the "training" accuracy achieved with the training images) and the blue line (the "validation" accuracy achieved when tested with images outside the training set).</span></span>

    ![TensorBoard スカラーの表示](../media-draft/3-tensorboard-scalars.png)

1. <span data-ttu-id="3d3a2-168">TensorBoard のメニューで **[グラフ]** をクリックして、表示されるグラフを調べます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-168">Click **GRAPHS** in the TensorBoard menu and inspect the graph shown there.</span></span> <span data-ttu-id="3d3a2-169">このグラフの主な目的は、ニューラル ネットワークとそれを構成するレイヤーを示すことです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-169">The primary purpose of this graph is to depict the neural network and the layers that comprise it.</span></span> <span data-ttu-id="3d3a2-170">この例では、"input_1" が食品イメージを使用してトレーニングされ、ネットワークに追加されたレイヤーです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-170">In this example, "input_1" is the layer that was trained with food images and added to the network.</span></span> <span data-ttu-id="3d3a2-171">"MobilenetV1" は、最初に使用する基本のニューラル ネットワークです。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-171">"MobilenetV1" is the base neural network that you started with.</span></span> <span data-ttu-id="3d3a2-172">これには、示されていない多くのレイヤーが含まれています。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-172">It contains many layers which aren't shown.</span></span> <span data-ttu-id="3d3a2-173">ゼロからディープ ニューラル ネットワークを構築した場合は、すべてのレイヤーがここにダイアグラム化されます。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-173">Had you built a deep neural network from scratch, all of the layers would have been diagrammed here.</span></span> <span data-ttu-id="3d3a2-174">(MobileNet を構成するレイヤーを表示する場合は、ダイアグラム内の "MobilenetV1" ブロックをダブルクリックします。)グラフの表示に関する情報とグラフに表示される情報については、「[TensorBoard: Graph Visualization](https://www.tensorflow.org/programmers_guide/graph_viz)」 (TensorBoard: グラフの視覚化) を参照してください。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-174">(If you would like to see the layers that comprise the MobileNet, double-click the "MobilenetV1" block in the diagram.) For more information on the Graphs display and the information surfaced there, refer to [TensorBoard: Graph Visualization](https://www.tensorflow.org/programmers_guide/graph_viz).</span></span>

    ![TensorBoard グラフの表示](../media-draft/3-tensorboard-graphs.png)

1. <span data-ttu-id="3d3a2-176">ファイル マネージャーに戻って、"notebooks/tensorflow-for-poets-2/tf_files" フォルダーに移動します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-176">Switch back to File Manager and navigate to the "notebooks/tensorflow-for-poets-2/tf_files" folder.</span></span> <span data-ttu-id="3d3a2-177">**retrained_graph_hotdog.pb** という名前のファイルが含まれていることを確認します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-177">Confirm that it contains a file named **retrained_graph_hotdog.pb**.</span></span> <span data-ttu-id="3d3a2-178">*このファイルは、トレーニング プロセス中に作成され、トレーニング済みの TensorFlow モデルが含まれています*。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-178">*This file was created during the training process and contains the trained TensorFlow model*.</span></span> <span data-ttu-id="3d3a2-179">次の演習では、これを使用して、NotHotDog アプリからモデルを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-179">You will use it in the next exercise to invoke the model from the NotHotDog app.</span></span>

<span data-ttu-id="3d3a2-180">手順 10 で実行したスクリプトでは、精度とトレーニングに必要な時間とのバランスを取るため、500 のトレーニング ステップを指定しました。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-180">The script that you executed in Step 10 specified 500 training steps, which strikes a balance between accuracy and the time required for training.</span></span> <span data-ttu-id="3d3a2-181">必要に応じて、```how_many_training_steps``` の値を 1000 または 2000 などに増やして、もう一度モデルのトレーニングを試してください。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-181">If you would like, try training the model again with a higher ```how_many_training_steps``` value such as 1000 or 2000.</span></span> <span data-ttu-id="3d3a2-182">通常は、ステップ数が多くなるほど精度が高まりますが、引き換えにトレーニング時間が長くなります。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-182">A higher step count generally results in higher accuracy, but at the expense of increased training time.</span></span> <span data-ttu-id="3d3a2-183">TensorBoard のスカラー表示でオレンジの線と青の線との差で示される、オーバー フィットに注意してください。</span><span class="sxs-lookup"><span data-stu-id="3d3a2-183">Watch out for overfitting, which, as a reminder, is represented by the difference between the orange and blue lines in TensorBoard's Scalars display.</span></span>